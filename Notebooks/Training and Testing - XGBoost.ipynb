{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhai\\Downloads\\Customer-Loyalty\\\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "if 'current_dir' in locals():\n",
    "    print(\"Directory has been set before:\")\n",
    "else:\n",
    "    current_dir = os.getcwd()[:-9] \n",
    "print(current_dir)\n",
    "os.chdir(current_dir + '/scripts')\n",
    "import preprocessing\n",
    "os.chdir(current_dir)\n",
    "submission = pd.read_csv(current_dir + 'submissions/submission_v1.csv') #submission as template (version is not important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhai\\Downloads\\Customer-Loyalty\n",
      "this is a train feature : train_feature_fam.csv\n",
      "this is a test feature : test_feature_fam.csv\n"
     ]
    }
   ],
   "source": [
    "train_x, train_l, testset_x = preprocessing.load_data(features=\"custom\", custom_features=[\"train_feature_fam.csv\",\"test_feature_fam.csv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Training will be done in the following cells. First a random part of the training data is assigned as training set and the leftovers will be the validation set. By making the _trainsize_ variable round(train.shape[0]/1), the entirety of the training data is used as training set, so no evaluation will be done in the section _Testing within training set_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First XGBoost model for Pima Indians dataset\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.83853\n",
      "Will train until train-rmse hasn't improved in 10 rounds.\n",
      "[1]\ttrain-rmse:3.8378\n",
      "[2]\ttrain-rmse:3.83761\n",
      "[3]\ttrain-rmse:3.8346\n",
      "[4]\ttrain-rmse:3.8346\n",
      "[5]\ttrain-rmse:3.8346\n",
      "[6]\ttrain-rmse:3.8346\n",
      "[7]\ttrain-rmse:3.8346\n",
      "[8]\ttrain-rmse:3.8346\n",
      "[9]\ttrain-rmse:3.8346\n",
      "Modeling RMSLE 3.83460\n"
     ]
    }
   ],
   "source": [
    "# fit model no training data\n",
    "# model = XGBClassifier()\n",
    "# model.fit(train_x, train_l)\n",
    "\n",
    "dtrain = xgb.DMatrix(train_x, train_l)\n",
    "watchlist = [(dtrain, 'train')]\n",
    "xgb_pars = {'min_child_weight': 0, 'eta': 1.0,'colsample_bytree': 0.9, \n",
    "        'max_depth': 100, 'subsample': 1., 'lambda': 0., 'nthread': 10, 'booster' : 'gbtree', 'silent': 1, 'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "model = xgb.train(xgb_pars, dtrain, 10, watchlist, early_stopping_rounds=10, maximize=False, verbose_eval=1)\n",
    "print('Modeling RMSLE %.5f' % model.best_score)\n",
    "\n",
    "## =====DEFAULT/COPIED PARAMETERS=====\n",
    "# dtrain = xgb.DMatrix(train_x, train_l)\n",
    "# watchlist = [(dtrain, 'train')]\n",
    "# xgb_pars = {'min_child_weight': 1, 'eta': 0.5, 'colsample_bytree': 0.9, \n",
    "#         'max_depth': 6, 'subsample': 0.9, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1, 'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "# model = xgb.train(xgb_pars, dtrain, 100, watchlist, early_stopping_rounds=10, maximize=False, verbose_eval=1)\n",
    "# print('Modeling RMSLE %.5f' % model.best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for test set (creating a submission .csv file)\n",
    "Make sure to use the entire training set in the the \"Training\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3 1 65]\n",
      " [2 3 0 62]\n",
      " [5 1 1 69]\n",
      " ...\n",
      " [5 1 1 58]\n",
      " [2 1 0 67]\n",
      " [5 1 1 59]]\n"
     ]
    }
   ],
   "source": [
    "print(testset_x)\n",
    "testset_x = xgb.DMatrix(testset_x)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(testset_x)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "submission.target = predictions\n",
    "# # evaluate predictions\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission was saved under the name:\u001b[1m submission_v0-005.csv\u001b[0;0m\n"
     ]
    }
   ],
   "source": [
    "# submission.target = submission_predictions\n",
    "\n",
    "for i in range(1,100,1):\n",
    "    if os.path.isfile('submissions/submission_v0-00' + str(i) + '.csv') == False:\n",
    "        submission.to_csv('submissions/submission_v0-00' + str(i) + '.csv', index = False)\n",
    "        print('Submission was saved under the name:' + '\\033[1m' ' submission_v0-00' + str(i) + '.csv' + '\\033[0;0m')\n",
    "        break\n",
    "\n",
    "# [Errno 13] Permission denied: 'submissions/submission_v0-001.csv'\n",
    "#        means that the file is still opened somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0     79115\n",
       "-1.0     43992\n",
       "-2.0       375\n",
       " 1.0        73\n",
       "-3.0        33\n",
       "-4.0        16\n",
       "-6.0         9\n",
       "-5.0         5\n",
       "-17.0        3\n",
       " 2.0         2\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this after previous cel to see the submission\n",
    "submission.target.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
